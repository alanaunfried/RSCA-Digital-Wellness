---
title: "Digital Wellness Validation"
author: Alana Unfried
date: last-modified
toc: true
number-sections: true
format:
  html:
    code-fold: true
    code-tools: true
    code-link: true
highlight-style: pygments
---

```{r}
#| label: packages
#| include: false

library(tidyverse)
library(haven)    #read in SPSS data
library(janitor)  #variable cleaning
library(gt)       #tables
library(ggformula)#df_stats
```

## Read In Data

Data file was provided via email from Jenn.

```{r}
#| include: false

#note ChatGPT was used to assist the creation of this code

#read in spss file using haven package
#note that SPSS value labels are labelled vectors; if you need plain, use as_factor() or zap_labels()
raw_data <- read_sav("data/Copy of Digital Wellness Survey_Merged_05.29.25_JL.sav")

#basic variable cleanup
data <- raw_data %>% 
  clean_names() # snake_case column names

#preview variables
head(data)

#variable labels
library(labelled)
look_for(data) |>
  as_tibble()
#can search for specific variables by key (also searches labels, case insensitive default)
#look_for(raw_data, "age")
#can just search variable names
#look_for(data, "age", labels=FALSE) %>%
#  as_tibble()

```

Preview of variable names

```{r}
names(data)
```

## Clean Data

Filter to population, etc.

```{r}

# #suspicious response filter does not remove any additional observations because all suspicious responses were for non-sona responses
# data |>
#   count(sona, suspicious_response)
# 
# #contingency table style
# data |>
#   count(sona, suspicious_response) |>
#   pivot_wider(names_from = suspicious_response,
#               values_from = n,
#               values_fill = 0)
  

# data |>
#   df_stats(~suspicious_response)


#note that the filter with not equal to will by default remove missing values!!
#so we filter to keep only when the value is missing for suspicious response
data_1 <- data |>
  filter(sona == 1) |> #removes 507 observations
  filter(is.na(suspicious_response)) |> #removes no additional observations
  filter(age >= 17, age <= 25) #filter age to emerging adulthood, removes 171 observations

```

### Investigate Hasty Responses

```{r}
library(careless)

#create new duration in minutes
data_1 <- data_1 |>
  mutate(duration_m = duration_in_seconds / 60)

#summary stats for duration
data_1 |>
  df_stats(~duration_m)

data_1 |>
  df_stats(duration_m~hasty_flag)

#can we look at % completed and compare to duration?
#not a priority right now

#remove responses based on hasty flag
#We are just following what Jenn already calculated so that data cleaning in general is with her in SPSS
data_2 <- data_1 |>
  filter(hasty_flag == 0)  #keeps if NOT hasty; remove 28 responses

```

### Missing Data

Investigate missing values just in the constructs. Remove any observations with too much data missing on digital wellness scale.

```{r}
#specify the variables that constitute the constructs
constructs <- data_2 |>
  select(c(id, social_1:sas_10)) |> #construct range + ID
  select(!c(validity_2, validity_1, physical_health)) |> #drop those not in a construct, now 134 vars
  mutate(n_miss = rowSums(across(social_1:sas_10, ~ is.na(.x)))) |> #calculate the number of missing values in each row
  mutate(n_miss_dws = rowSums(across(social_1:emotional_18, ~ is.na(.x)))) #mising just on DWS

#table of missing values sorted from highest to lowest. #most missing is 87 our of 134
constructs |> 
  select(id, n_miss:n_miss_dws) |>
  arrange(desc(n_miss_dws))  |>
  head()

#based on this we will remove IDs 1066 and 70. Keeping the row that has missing values but fully answered the DWS
constructs_1 <- constructs |> 
  filter(!id %in% c(1066, 70)) 

#summary of missingness after removal
constructs_1 |> 
  ggplot(aes(x=n_miss_dws)) +
  geom_histogram()

constructs_1 |>
  df_stats(~n_miss_dws)

constructs_1 |> 
  ggplot(aes(x=n_miss)) +
  geom_histogram()

constructs_1 |>
  df_stats(~n_miss)


#remove the 2 problematic rows in the original data
data_3 <- data_2 |> 
  filter(!id %in% c(1066, 70))
```

### Imputation

We will impute missing values just based on construct scores. But, I should revisit the MASDER data cleaning protocol to see if we imputed also on demographics.

```{r}

```

## EDA

Model after S-SOMAS Pilot 0 paper

```{r}

```
